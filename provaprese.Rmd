---
title: "Does Elon Musk's tweets influence Bitcoin market value? : A sentiment anaylsis approach"
author: "Beatrice Stocco - Federico Piazza - Luigi Negro"
date: "04/04/2022"
output:
  beamer_presentation:
    slide_level: 2
    latex_engine: xelatex
---


```{r load-packages, include=FALSE}
if(!require(dplyr)) install.packages("dplyr")
if(!require(tidyverse)) install.packages("tidyverse")
if(!require(readxl)) install.packages("readxl")
library(dplyr)
library(tidyverse)
library(ggplot2)
if(!require(hrbrthemes)) install.packages("hrbrthemes")
library(hrbrthemes)
#install.packages("ggthemes")
library(ggthemes)
#library(readxl)
library(tidyr)
library(crypto2)
library(lubridate)
library(stringr)
if(!require(tm)) install.packages("tm")
library(tm)
library(RColorBrewer)
library(wordcloud)
if(!require(wordcloud2)) install.packages("wordcloud2")
library(wordcloud2)
library(syuzhet)
library(scales)
library(reshape2)
library(devtools) 
library(sentimentr)
library(e1071)
library(gridExtra)
if(!require(tseries)) install.packages("tseries")
options(warn=-1)
library(tseries)
if(!require(changepoint)) install.packages("changepoint")
library(changepoint)
library(ggpubr)

```

## Agenda

- Conceptual Background and Research Questions 
- Explanatory Data Analysis
- Sentiment Analysis
- Testing for Stationarity 
- Conclusion

## Agenda

- **Conceptual Background and Research Questions** 
- Explanatory Data Analysis
- Sentiment Analysis
- Testing for Stationarity
- Conclusion



## Conceptual background 

Our work is based on the following conceptual fundamentals:

- Individuals tweets' have tangible impact on stock market returns. *(Kinyua et. al, 2021)*

- Emotions have been proved to be key drivers in the process of investing. *(Philippas et al., 2019)*

- Twitter can be used as a predictor of real world landscape. *(Huaye and Yasuaki, 2015)*


## Research questions

*RQ1*: What is the polarity and the most-used emotions in Elon Musk's tweets?

*RQ2*: Do sentiments and polarity of Musk’s cryptocurrency-related tweets differs by considering different time-frames and currencies

*RQ3*: Is there a linkage between changes in Bitcoin prices and Elon Musk's crpyto-related tweets?


## Elon Musk's tweets make Bitcoin price skyrocket

" Bitcoin’s structure is very ingenious. The paper money disappears, and crypto-currencies are a much better way to transfer values than a piece of paper, that’s for sure "

"I think bitcoin is on the verge of getting broad acceptance by conventional finance people"

## Elon's tweet making BTC skyrocket...


![](imageBitcoinMask.jpg){height=90%}


## ..as well as going down


![](notTesla.jpg){height=90%}


## Indeed

![](events_image.jpg)



## Agenda

- Literature Review and Conceptual Background
- **Explanatory Data Analysis**
- Sentiment Analysis
- Testing for Stationarity
- Conclusion

## EDA: Popularity

Exploiting twitter APIs, Tesla's CEO tweets from 2011 to 2021 were extracted. 
The following variables were used as proxy to investigate Elon Musks's growing popularity: number of *retweets*, number of *likes* and number of *replies* per year, together with a comparison with the total tweets activity. Results are shown in the following chart:

```{r, include=FALSE}
elon =  read.csv("elon.csv")
dim(elon)
head(elon)

#create a dataset for analysing popularity

popularity = as.data.frame(cbind(elon$tweet, elon$nlikes, elon$nreplies, elon$nretweets, elon$date))
#change the col names
colnames(popularity) = c("tweet", "nlikes","nreplies", "nretweets", "date")

#Showing summaries of each variable

#install.packages("hrbrthemes")

popularity$date <- format(as.POSIXct(popularity$date,format="%Y-%m-%d %H:%M:%OS"),format='%m/%d/%Y')
 

popularity$date <- as.Date(as.character(popularity$date), format='%m/%d/%Y')
popularity$nreplies= as.numeric(popularity$nreplies)
popularity$nretweets= as.numeric(popularity$nretweets)
popularity$nlikes= as.numeric(popularity$nlikes)


#grouping by year 

tweets_year<- popularity %>%
mutate(dates = as.Date(popularity$date)) %>%
mutate(yr = format(dates, '%Y')) %>%
group_by(yr) %>%
summarise(tweet=n())

likes_year <- popularity %>%
mutate(dates = as.Date(popularity$date)) %>%
mutate(yr = format(dates, '%Y')) %>%
group_by(yr) %>%
summarise(nlikes=sum(nlikes))

retweet_year <- popularity %>%
mutate(dates = as.Date(popularity$date)) %>%
mutate(yr = format(dates, '%Y')) %>%
group_by(yr) %>%
summarise(nretweets = sum(nretweets))

nreplies_year <- popularity %>%
mutate(dates = as.Date(popularity$date)) %>%
mutate(yr = format(dates, '%Y')) %>%
group_by(yr) %>%
summarise(nreplies = sum(nreplies))

#removing year 2022 

nreplies_year= nreplies_year[-c(12), ]
retweet_year= retweet_year[-c(12), ]
likes_year= likes_year[-c(12), ]
tweets_year = tweets_year[-c(12), ]



Replies = nreplies_year$nreplies
Likes =  likes_year$nlikes
Retweets = retweet_year$nretweets
summary(cbind(Replies, Retweets, Likes))

#numeric 

nreplies_year$nreplies= as.numeric(nreplies_year$nreplies)
nreplies_year$yr= as.numeric(nreplies_year$yr)

retweet_year$yr = as.numeric(retweet_year$yr)
retweet_year$nretweets = as.numeric(retweet_year$nretweets)

likes_year$yr = as.numeric(likes_year$yr)
likes_year$nlikes = as.numeric(likes_year$nlikes)

tweets_year$yr = as.numeric(tweets_year$yr)
tweets_year$tweet = as.numeric(tweets_year$tweet)

#plot
```

## EDA: Popularity

```{r, echo=FALSE}
library(ggplot2)
tweets <- ggplot(data = tweets_year, aes(x = yr, y = tweet)) + 
  geom_bar(stat = "identity", width = 0.5, position = "dodge", fill = "purple", color = "black") + 
  xlab("Year") +
  ylab("Number of tweets")  +
  ggtitle("Tweets per year") +
  theme(plot.title = element_text(hjust = 0.5)) +
  theme_minimal()

likes <- ggplot(data = likes_year, aes(x = yr, y = nlikes)) + 
  geom_bar(stat = "identity", width = 0.5, position = "dodge", fill = "darkorange", color = "black") + 
  xlab("Year") +
  ylab("Number of likes")  +
  ggtitle("Likes per year") +
  theme(plot.title = element_text(hjust = 0.5)) +
  theme_minimal()

retweets <- ggplot(data =retweet_year, aes(x = yr, y = nretweets), color ="darkorange") + 
  geom_bar(stat = "identity", width = 0.5, position = "dodge", fill = "dark green", color = "black") + 
  xlab("Year") +
  ylab("Number of retweets") +  
   ggtitle("Retweets per year") +
  theme(plot.title = element_text(hjust = 0.5)) +
  theme_minimal()

replies <- ggplot(data = nreplies_year, aes(x = yr, y = nreplies)) + 
  geom_bar(stat = "identity", width = 0.5, position = "dodge", fill ="dark red", color ="black") + 
  xlab("Year") +
  ylab("Number of replies")  +  
   ggtitle("Replies per year") +
  theme(plot.title = element_text(hjust = 0.5)) +
  theme_minimal()

ggarrange(tweets, likes, retweets, replies, 
          ncol = 2, nrow = 2)

```


## Crypto-related tweets

Consequently, we compare how Elon Musk's audience react to different type of tweets containing respectevely words related only to *dogecoin*, *Bitcoin* and *crypto*. The same proxies as before have been used.


```{r, include=FALSE}
#subsetting in order to undersand tweet share


elondoge = elon[grepl("dogecoin", elon[["tweet"]]) | grepl("Doge", elon[["tweet"]]) | grepl("doge", elon[["tweet"]]),]
elonCryptoOnly = elon[grepl("crypto", elon[["tweet"]]) | grepl("Crypto", elon[["tweet"]]) | grepl("cryptos", elon[["tweet"]]),]
elonBTC = elon[grepl("BTC", elon[["tweet"]])| grepl("Bitcoin", elon[["tweet"]])| grepl("bitcoin", elon[["tweet"]]),]

n_doge = length(elondoge$tweet)
n_onlycrypto = length(elonCryptoOnly$tweet)
n_BTC = length(elonCryptoOnly$tweet)
n_totaltweet = n_doge + n_onlycrypto + n_BTC

#vector 

vectorshare = c(n_doge, n_onlycrypto, n_BTC)
vectorshare= as.data.frame(vectorshare)
dim(vectorshare)
colnames(vectorshare) = c("tweetcount")
rownames(vectorshare) = c("doge", "crypto", "BTC")

#counting total nlikes, nreplies, nretweet per each keyword to understand where is the maximum activity
## like
n_dogelikes = mean(elondoge$nlikes)
n_onlycrptolikes = mean(elonCryptoOnly$nlikes)
n_BTClike = mean(elonBTC$nlikes)
n_totallike = mean(elon$nlikes)
##retweet
n_dogeretweet = mean(elondoge$nretweets)
n_onlycrptoretweet = mean(elonCryptoOnly$nretweets)
n_BTCretweet = mean(elonBTC$nretweets)
n_totalretweet = mean(elon$nretweets)

##reply
n_dogereply = mean(elondoge$nreplies)
n_onlycrptoreply = mean(elonCryptoOnly$nreplies)
n_BTClreply= mean(elonBTC$nreplies)
n_totalreply = mean(elon$nreplies)



#dataframe activity
vectoractivity_doge= c(n_dogelikes, n_dogereply, n_dogeretweet)
vectoractivity_BTC= c(n_BTClike, n_BTClreply, n_BTCretweet)
vectoractivity_crypto = c(n_onlycrptolikes, n_onlycrptoreply, n_onlycrptoretweet)
vectoractivity_total = c(n_totallike, n_totalreply, n_totalretweet)
dfactivity = cbind(vectoractivity_doge, vectoractivity_crypto, vectoractivity_BTC, vectoractivity_total)
dfactivity = t(dfactivity)
dfactivity = as.data.frame(dfactivity)
dfactivity$crypto = c("ActivityDoge", "ActivityCrypto", "ActivityBTC", "TotalActivity")
rownames(dfactivity) = c("ActivityDoge", "ActivityCrypto", "ActivityBTC", "TotalActivity")
colnames(dfactivity) = c("Likes", "Replies", "Retweets", "Total")
```

## Crypto-related tweets 

```{r, echo=FALSE}
dfactivity %>%
  gather(key, value, -Total) %>% 
  ggplot(aes(x=Total, y=value, fill = key)) +
  geom_col(position = "dodge") +
  theme_minimal()
```


## Bitcoin trend

Which is the width of Bitcoin price volatility once a crypto-related tweets is published? We managed to extract the tweets which only cointained the words *bitcoin* and *crypto* and connected their time-stamp to the Bitcoin market capitalization trend. The pink points on the graphic represent the moment in time when a crpyto-related tweet was published.

Can we infere something? Maybe..

```{r, include=FALSE}
# install.packages("devtools")
#devtools::install_github("sstoeckl/crypto2", force=TRUE)

#take daily hist of BTC
coins <- crypto_list(only_active=TRUE)
btc_hist <- crypto_history(coins, limit=1, start_date="20110101", end_date="20220131")

as.data.frame(btc_hist)
btc_hist$timestamp <- format(as.POSIXct(btc_hist$timestamp,format="%Y-%m-%d %H:%M:%OS"),format='%m/%d/%Y')
btc_hist$timestamp <- as.Date(as.character(btc_hist$timestamp), format='%m/%d/%Y')


#subset tweets keeping those that contains ("bitcoin","crypto")
eloncrypto <- elon[grepl("crypto", elon[["tweet"]]) | grepl("BTC", elon[["tweet"]]),]
as.data.frame(eloncrypto)
eloncrypto$date <- format(as.POSIXct(eloncrypto$date,format="%Y-%m-%d %H:%M:%OS"),format='%m/%d/%Y')
eloncrypto$date <- as.Date(as.character(eloncrypto$date), format='%m/%d/%Y')
btc_hist['tweet'] <- btc_hist$timestamp %in% eloncrypto$date
```

## Maybe not?

```{r, echo=FALSE}
btc_hist[1500:3200,] %>%
ggplot(aes(x = timestamp, y = open)) +
geom_line() + 
geom_point(data = . %>% filter(tweet == TRUE), color = "deeppink", size = 3) +
ggtitle("Elon Musk's Tweets and Bitcoin Volatility") +
theme(plot.title = element_text(hjust = 0.5)) +
  theme_minimal()

```

## Agenda

- Conceptual Background and Research Questions
- Explanatory Data Analysis
- **Sentiment Analysis**
- Testing for Stationarity
- Conclusion


## Sentiment Analysis

Once quantified Elon Musk's influence, it is essential to understand the extent of this influence on the cryptomarket. We will try to answer the following questions:

- Which are the sentiments expressed by Elon Musk's tweets?
- Which are the most frequent words?
- Which is the polarity of this sentiments?

## Modelisation

We will use two subsets and consequently two models:
\begin{itemize}
  \item Model I: investigation conducted on the entire dataset containing all Elon Musk's tweets from 2011 to 2021.
  \item Model II: investigation conducted on a subset according to the following criteria:
   \begin{itemize}
       \item Temporal subset: we select the tweets published from January 2020 on, in order to assess results related to a maturity-stage Elon Musk's popularity
       \item Most frequent word removal: we removed the most frequent word *AMP* resulted from **Model I**
   \end{itemize}
\end{itemize}

This will be the first step to gather more information in order to assess whether the previous chart could actually show a link betweeen Bitcoin's volatility and Musk's tweets


## Sentiment analysis

While the market may interpret Musk's tweets about Tesla as “accurate news”, his tweets about cryptocurrency at least to some degree represent moods or personal sentiment. In this slide we show the nature of this sentiments, the most frequent words and the emotions associated to them for each of the models.


```{r, include=FALSE}
#!all the code will be needed for the presentation, therefore i write all the lines so to use the plot at the end

## MODEL 1

corpus <- iconv(elon$tweet)
corpus <- Corpus(VectorSource(corpus))
inspect(corpus[1:5])
#clean
corpus <- tm_map(corpus, tolower)
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, removeNumbers)
cleanset <- tm_map(corpus, removeWords, stopwords('english'))
removeURL <- function(x) gsub('http[[:alnum:]]*', '', x)
cleanset <- tm_map(cleanset, content_transformer(removeURL))
inspect(cleanset[1:10])
#stemming = reduce to root form
cleanset <- tm_map(cleanset, stripWhitespace)
inspect(cleanset[1:5])

tdm <- TermDocumentMatrix(cleanset)
tdm <- as.matrix(tdm)
tdm[1:10, 1:20]
words <- rowSums(tdm)
words <- subset(words, words>=120)
words <- as.data.frame(words)
words$names <- rownames(words)

#scores and density
s <- get_nrc_sentiment(elon$tweet)
head(s)

s_graph <- colSums(s)
s_graph <- as.data.frame(s_graph)
s_graph$emotions <- rownames(s_graph)
s_graph$count <- s_graph$s_graph

#sentiment
#install_github("trinker/sentimentr") 

txt <- elon$tweet
#txt cleaning

#txt <- sapply(txt, function(x) iconv(x, to='UTF-8-MAC', sub='byte'))
#for Windows based OS
txt <- sapply(txt,function(row) iconv(row, "latin1", "ASCII", sub=""))
#remove punctuation
txt = gsub("(RT|via)((?:\\b\\W*@\\w+)+)", "", txt)
# remove at people
txt = gsub("@\\w+", "", txt)
# remove punctuation
txt = gsub("[[:punct:]]", "", txt)
# remove numbers
txt = gsub("[[:digit:]]", "", txt)
# remove html links
txt = gsub("http\\w+", "", txt)
# remove unnecessary spaces
txt = gsub("[ \t]{2,}", "", txt)
txt = gsub("^\\s+|\\s+$", "", txt)
txt = txt[!is.na(txt)]
names(txt) = NULL


sentiment_by(txt) 

t = extract_sentiment_terms(txt) 


attributes(t)$count

#density plot
txt %>%
get_sentences() %>%
sentiment() %>%
filter(sentiment!=0) -> senti

#summary statistics model I
densitySentiments <- density(senti$sentiment) 
meanSentiTot= mean(senti$sentiment)
sdSentiTot= sd(senti$sentiment)
skewnessSentiTot= skewness(senti$sentiment)
kurtosisSentiTot= kurtosis(senti$sentiment)
IQR = IQR(senti$sentiment)

#table statistics model I
summarizeStatSenti = c(meanSentiTot, sdSentiTot, IQR, skewnessSentiTot, kurtosisSentiTot)
summarizeStatSenti = data.frame((summarizeStatSenti))
rownames(summarizeStatSenti) = c("Mean", "Sd", "IQR", "Skewness", "Kurtosis")
colnames(summarizeStatSenti) = "Statistical summary sentiment"
summarizeStatSenti



## MODEL 2 
tweet2020 = elon
tweet2020 = tweet2020[-c(1:2762),]

#eliminate tweet containing "amp" with grepl
tweet2020 = tweet2020[!grepl("amp", tweet2020[["tweet"]]),]


corpus1 <- iconv(tweet2020$tweet)
corpus1 <- Corpus(VectorSource(corpus1))
inspect(corpus1[1:6])
#clean
corpus1 <- tm_map(corpus1, tolower)
corpus1<- tm_map(corpus1, removePunctuation)
corpus1 <- tm_map(corpus1, removeNumbers)
cleanset1 <- tm_map(corpus1, removeWords, stopwords('english'))
removeURL1 <- function(x) gsub('http[[:alnum:]]*', '', x)
cleanset1 <- tm_map(cleanset1, content_transformer(removeURL1))
inspect(cleanset1[1:10])
#stemming = reduce to root form
cleanset1 <- tm_map(cleanset1, stripWhitespace)
inspect(cleanset1[1:5])

#words

tdm1 <- TermDocumentMatrix(cleanset1)
tdm1 <- as.matrix(tdm1)
tdm1[1:10, 1:20]
words1 <- rowSums(tdm1)
words1 <- subset(words1, words1>=60)
words1 <- as.data.frame(words1)
words1$names <- rownames(words1)


#density 
s1 <- get_nrc_sentiment(tweet2020$tweet)
head(s1)
s1_graph <- colSums(s1)
s1_graph <- as.data.frame(s1_graph)
s1_graph$emotions <- rownames(s1_graph)
s1_graph$count <- s1_graph$s1_graph


txt1 <- tweet2020$tweet
#txt cleaning

#txt <- sapply(txt, function(x) iconv(x, to='UTF-8-MAC', sub='byte'))
#for Windows based OS
txt1 <- sapply(txt1,function(row) iconv(row, "latin1", "ASCII", sub=""))
#remove punctuation
txt1 = gsub("(RT|via)((?:\\b\\W*@\\w+)+)", "", txt1)
# remove at people
txt1 = gsub("@\\w+", "", txt1)
# remove punctuation
txt1 = gsub("[[:punct:]]", "", txt1)
# remove numbers
txt1 = gsub("[[:digit:]]", "", txt1)
# remove html links
txt1 = gsub("http\\w+", "", txt1)
# remove unnecessary spaces
txt1 = gsub("[ \t]{2,}", "", txt1)
txt1 = gsub("^\\s+|\\s+$", "", txt1)
txt1 = txt1[!is.na(txt1)]
names(txt1) = NULL

sentiment_by(txt1) 

t1 = extract_sentiment_terms(txt1) 


attributes(t1)$count

#txt 

txt1 %>%
get_sentences() %>%
sentiment() %>%
filter(sentiment!=0) -> senti1

#statstical summary model II

densitySentiments1 <- density(senti1$sentiment) 
meanSentiTot1= mean(senti1$sentiment)
sdSentiTot1= sd(senti1$sentiment)
skewnessSentiTot1= skewness(senti1$sentiment)
kurtosisSentiTot1= kurtosis(senti1$sentiment)
IQR1 = IQR(senti1$sentiment)
summarizeStatSenti1 = c(meanSentiTot1, sdSentiTot1, IQR1, skewnessSentiTot1, kurtosisSentiTot1)
summarizeStatSenti1 = data.frame(summarizeStatSenti1)
rownames(summarizeStatSenti1) = c("Mean", "Sd", "IQR", "Skewness", "Kurtosis")
colnames(summarizeStatSenti1) = "Statistical summary sentiment"
summarizeStatSenti2 = bind_cols(summarizeStatSenti1, summarizeStatSenti)
colnames(summarizeStatSenti2) = c("Sentiment model I", "Sentiment model II")
summarizeStatSenti2
```


```{r fig56, echo=FALSE, fig.width=7,fig.height=4}
#plot most used words two models

sentiwords1 <- ggplot(data=words, aes(x=reorder(names, words), y=words)) +
  labs(y = "Words", x = "Count", title = "Word frequency Model I") +
  geom_bar(stat="identity", aes(fill=words)) +
  theme(axis.text.x=element_text(angle=45, hjust=1)) +
  scale_fill_gradient2(low = "blue", high = "darkblue") +
  coord_flip() +
  theme_minimal()

sentiwords2 <-ggplot(data=words1, aes(x=reorder(names, words1), y=words1)) +
    labs(y = "Words", x = "Count", title = "Word frequency Model II") +
  geom_bar(stat="identity", aes(fill=words1)) +
  theme(axis.text.x=element_text(angle=45, hjust=1)) +
  scale_fill_gradient2(low = "blue", high = "darkblue") +
  coord_flip() +
  theme_minimal()

ggarrange(sentiwords1, sentiwords2, ncol =2, nrow = 1)



```



## Sentiment scores and density

Based on the following results of the Sentiment Analysis of Elon Musk's tweets, it appears clear that *positive*, *trust* and *anticipation* are the most frequent emotions

```{r fig6, echo=FALSE, fig.width=7,fig.height=3,fig.cap="\\label{fig:fig6}Sentiment scores of Elon's tweets"}
scores1 <- ggplot(data=s_graph, aes(x=reorder(emotions, count), y=count)) +
  geom_bar(stat="identity", aes(fill=count)) +
  theme(axis.text.x=element_text(angle=45, hjust=1)) +
  scale_fill_gradient2(low = "yellow", high = "red") +
  coord_flip() +
  labs(title="Sentiment Scores Tweets", x="emotions") +
  theme_minimal()

scores2 <- ggplot(data=s1_graph, aes(x=reorder(emotions, count), y=count)) +
  geom_bar(stat="identity", aes(fill=count)) +
  theme(axis.text.x=element_text(angle=45, hjust=1)) +
  scale_fill_gradient2(low = "yellow", high = "red") +
  coord_flip() +
  labs(title="Sentiment Scores Tweets", x="emotions") +
  theme_minimal()

ggarrange(scores1, scores2, ncol =2, nrow = 1)

```

## Polarity Scores

```{r fig7, echo=FALSE, fig.width=7,fig.height=3,fig.cap="\\label{fig:fig7}density of polarity scores"}
par(mfrow=c(1,2))
plot(densitySentiments,main='Density of sentiments Model I') 
mtext("Mean = 0.1824", side=3)
polygon(densitySentiments,col='red')
plot(densitySentiments1,main='Density of sentiments Model II') 
mtext("Mean = 0.1981", side=3)
polygon(densitySentiments1,col='green') 
```


## Emotions

```{r, echo=FALSE}
e1<-emotion_by(get_sentences(txt1),drop.unused.emotions=TRUE)
plot(e1)
```


## Agenda

- Conceptual Background and Research Questions
- Explanatory Data Analysis
- Sentiment Analysis
- **Testing for Stationarity**
- Conclusion


## Stationarity 

In this section we show the results obtained when testing for Bitcoin and Dogecoin trend stationarity. We recall the hypothesis:

*Null Hypothesis (H0)* : Null hypothesis of the test is that the time series can be represented by a unit root that is not stationary.
*Alternative Hypothesis (H1)*: Alternative Hypothesis of the test is that the time series is stationary. The following plot, represent our study focus.

We perform an augmented Dickey–Fuller test (ADF) to test the null hypothesis that a unit root is present in a time series sample. In our case Bitcoin Sample and Dogecoin sample, respectevely.

## Result 

Satisfying results have been achieved on a *logdiff* transformation of the trend: the difference between two consecutive values, in *log* terms.
```{r, include=FALSE, echo = FALSE}
#Bitcoin
par(mfrow=c(2,1))
plot(btc_hist$timestamp,btc_hist$open,
     type='l',col='red',
     xlab = "time (t)",
     ylab = "Y(t)",
     main = "Trend signal")
acf(btc_hist$open,lag.max = length(btc_hist$open),
         xlab = "lag #", ylab = 'ACF', main=' ')

par(mfrow=c(2,1))
btc_hist['log'] = log(btc_hist$open)
plot(btc_hist$timestamp,btc_hist$log,
     type='l',col='red',
     xlab = "time (t)",
     ylab = "Y(t)",
     main = "Trend signal")
acf(btc_hist$log,lag.max = length(btc_hist$log),
         xlab = "lag #", ylab = 'ACF', main=' ')
```


```{r fig66, echo = FALSE}
par(mfrow=c(2,1))
logdiff = diff(btc_hist$log)

plot(btc_hist$timestamp[2:3200],logdiff,
     type='l',col='red',
     xlab = "time (t)",
     ylab = "Y(t)",
     main = "Trend signal")
acf(logdiff,lag.max = length(btc_hist$open),
         xlab = "lag #", ylab = 'ACF', main=' ')
```


```{r, include =FALSE}
#dogecoin

doge <- crypto_list(only_active=TRUE)
doge <- subset(doge, doge$slug == "dogecoin")
doge_hist <- crypto_history(doge, limit=1, start_date="20200101", end_date="20220131")

par(mfrow=c(2,3))
plot(doge_hist$timestamp,doge_hist$open,
     type='l',col='red',
     xlab = "time (t)",
     ylab = "Y(t)",
     main = "Trend signal")
acf(doge_hist$open,lag.max = length(doge_hist$timestamp),
         xlab = "lag #", ylab = 'ACF', main=' ')

dogelogdiff = diff(log(doge_hist$open))

```

 
## Breaking Points

```{r, include=FALSE}
m_binseg <- cpt.mean(logdiff[2750:3199], penalty = "None", method = "BinSeg", Q = 15)
```

```{r fig17, echo=FALSE, fig.width=6,fig.height=5,fig.cap="\\label{fig:fig17}Changepoints in LogBitcoin Differences"}
plot(m_binseg, type = "l", xlab = "Index", cpt.width = 4)
```


```{r, include=FALSE}
# bitcoin 

BTC_TREND_BR= plot(btc_hist$timestamp[2:3200],logdiff,
     type='l',col='red',
     xlab = "time (t)",
     ylab = "Y(t)",
     main = "Trend signal")
acf(logdiff,lag.max = length(btc_hist$open),
         xlab = "lag #", ylab = 'ACF', main=' ')
#dogecoin


doge_TREND_BR = plot(doge_hist$timestamp[2:760],dogelogdiff,
     type='l',col='red',
     xlab = "time (t)",
     ylab = "Y(t)",
     main = "Trend signal")
acf(dogelogdiff,lag.max = length(doge_hist$timestamp),
         xlab = "lag #", ylab = 'ACF', main=' ')

# one next to the other

ggarrange(BTC_TREND_BR, doge_TREND_BR, nrow =2, ncol=1)
```

## Tweets and Breakpoints Timestamp Bitcoin

```{r, include=FALSE}
cpt_date = btc_hist$timestamp[2749] + cpts(m_binseg) 
tweet_date = btc_hist %>% filter(tweet == TRUE) %>% select(timestamp)
eloncrypto <- elon[grepl("crypto", elon[["tweet"]]) | grepl("BTC", elon[["tweet"]]),]
as.data.frame(eloncrypto)
cpt_date <- format(as.POSIXct(cpt_date,format="%Y-%m-%d %H:%M:%OS"),format='%m/%d/%Y')
cpt_date <- as.Date(as.character(cpt_date), format='%m/%d/%Y')

btc_hist['breakpoint'] <- btc_hist$timestamp %in% cpt_date
```


```{r fig25, echo=FALSE, fig.width=7,fig.height=6,fig.cap="\\label{fig:fig25}Elon Musk's Tweets on Cryptos and LogBTC's Changing Points Dates"}

colors <- c("tweets" = "steelblue",  "breakingpoints" = "red")
btc_hist[2750:3200,] %>%
ggplot(aes(x = timestamp, y = open)) + geom_line() +
geom_point(data = . %>% filter(tweet == TRUE), aes(color = "tweets"), size = 3) +
geom_point(data = . %>% filter(breakpoint == TRUE), aes(color = "breakingpoints"), size = 3) + 
ggtitle("Elon Musk's Tweets and Breaking Points") +
theme(plot.title = element_text(hjust = 0.5)) +
labs(x = "timestamp",
         y = "BTC value",
         color = "Legend") + scale_color_manual(values = colors) +
theme_minimal()

```

## Tweets and Breakpoints Timestamp Dogecoin


```{r, include=FALSE}
as.data.frame(btc_hist)
doge_hist$timestamp <- format(as.POSIXct(doge_hist$timestamp,format="%Y-%m-%d %H:%M:%OS"),format='%m/%d/%Y')
doge_hist$timestamp <- as.Date(as.character(doge_hist$timestamp), format='%m/%d/%Y')
doge_m_binseg <- cpt.mean(dogelogdiff, penalty = "None", method = "BinSeg", Q = 15)

doge_cpt_date = doge_hist$timestamp[1] + cpts(doge_m_binseg) 
doge_cpt_date <- format(as.POSIXct(doge_cpt_date,format="%Y-%m-%d %H:%M:%OS"),format='%m/%d/%Y')
doge_cpt_date <- as.Date(as.character(doge_cpt_date), format='%m/%d/%Y')

doge_hist['breakpoint'] <- doge_hist$timestamp %in% doge_cpt_date

dogecrypto <- elon[grepl("Doge", elon[["tweet"]]) | grepl("dogecoin", elon[["tweet"]]),]
as.data.frame(dogecrypto)
dogecrypto$date <- format(as.POSIXct(dogecrypto$date,format="%Y-%m-%d %H:%M:%OS"),format='%m/%d/%Y')
dogecrypto$date <- as.Date(as.character(dogecrypto$date), format='%m/%d/%Y')
doge_hist['tweet'] <- doge_hist$timestamp %in% dogecrypto$date
```


```{r fig21, echo=FALSE, fig.width=7,fig.height=6,fig.cap="\\label{fig:fig21}Elon Musk's Tweets on Dogecoin and LogDoge's Changing Points Dates"}
colorsD <- c("tweets" = "green",  "breaking points" = "orange")
doge_hist[300:760,] %>%
ggplot(aes(x = timestamp, y = open)) +
geom_line() + 
geom_point(data = . %>% filter(tweet == TRUE), aes(color = "tweets"), size = 3) +
geom_point(data = . %>% filter(breakpoint == TRUE), aes(color = "breaking points"), size = 3) +  
ggtitle("Elon Musk's Tweets and Breaking Points") +
theme(plot.title = element_text(hjust = 0.5)) +
labs(x = "timestamp",
         y = "DOGE value",
         color = "Legend") + scale_color_manual(values = colorsD) +
theme_minimal()
```


## Agenda

- Conceptual Background and Research Questions
- Explanatory Data Analysis
- Sentiment Analysis
- Testing for Stationarity
- **Conclusion**

## Conclusion

We have extracted a total of 4787 tweets containing 68676 words from Elon Musk’s twitter profile: we investigate the impact of 26 Twitter events by Elon Musk on the trading volume and price of the cryptocurrencies he comments on. 

Two models:
\begin{itemize}
  \item Model I: investigation conducted on the entire dataset containing all Elon Musk's tweets from 2011 to 2021.
  \item Model II: investigation conducted on a subset according to the following criteria:
   \begin{itemize}
       \item Temporal subset: we select the tweets published from January 2020 on, in order to assess results related to a maturity-stage Elon Musk's popularity
       \item Most frequent word removal: we removed the most frequent word *AMP* resulted from **Model I**
   \end{itemize}
\end{itemize}

## Conclusion

- Popularity assessment
- Sentiment analysis
- Testing for stationarity
- Breaking points and tweets timestamp

Key conclusions:

- Elon Musk influence has grown up exponentially throughout the years and its activity's volume show that his tweets are seen as valuable market's signal by investors
- Its sentiments are overall positive, full of confidence and boldness
- No linkage can be found in its tweet activity and crypto-currency (Bitcoin and Doge) volatility 


