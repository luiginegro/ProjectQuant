<<<<<<< HEAD
xlab("Year") +
ylab("Number of replies")  +
theme_minimal() +
scale_fill_brewer(direction = -1)
ggplot(data = likes_year, aes(x = yr, y = nlikes)) +
geom_bar(stat = "identity", width = 0.5, position = "dodge", fill = "darkorange") +
xlab("Year") +
ylab("Number of likes")  +
theme_minimal() +
scale_fill_brewer(direction = -1)
par(mfrow=c(3,1))
ggplot(data = likes_year, aes(x = yr, y = nlikes)) +
geom_bar(stat = "identity", width = 0.5, position = "dodge", fill = "darkorange") +
xlab("Year") +
ylab("Number of likes")  +
theme_minimal() +
scale_fill_brewer(direction = -1)
ggplot(data = likes_year, aes(x = yr, y = nlikes)) +
geom_bar(stat = "identity", width = 0.5, position = "dodge", fill = "darkorange") +
xlab("Year") +
ylab("Number of likes")  +
theme_minimal() +
scale_fill_brewer(direction = -1)
ggplot(data = likes_year, aes(x = yr, y = nlikes)) +
geom_bar(stat = "identity", width = 0.5, position = "dodge", fill = "darkorange", color = "black") +
xlab("Year") +
ylab("Number of likes")  +
labs(fill = "Isic Code")  +
theme_minimal() +
scale_fill_brewer(direction = -1)
ggplot(data =retweet_year, aes(x = yr, y = nretweets), color ="darkorange") +
geom_bar(stat = "identity", width = 0.5, position = "dodge", fill = "dark green") +
xlab("Year") +
ylab("Number of retweets") +
theme_minimal() +
scale_fill_brewer(direction = -1)
ggplot(data =retweet_year, aes(x = yr, y = nretweets), color ="darkorange") +
geom_bar(stat = "identity", width = 0.5, position = "dodge", fill = "dark green", color = "black") +
xlab("Year") +
ylab("Number of retweets") +
theme_minimal() +
scale_fill_brewer(direction = -1)
ggplot(data = nreplies_year, aes(x = yr, y = nreplies)) +
geom_bar(stat = "identity", width = 0.5, position = "dodge", fill ="dark red") +
xlab("Year") +
ylab("Number of replies")  +
theme_minimal() +
scale_fill_brewer(direction = -1)
ggplot(data = nreplies_year, aes(x = yr, y = nreplies)) +
geom_bar(stat = "identity", width = 0.5, position = "dodge", fill ="dark red", color ="black") +
xlab("Year") +
ylab("Number of replies")  +
theme_minimal() +
scale_fill_brewer(direction = -1)
ggplot(data = nreplies_year, aes(x = yr, y = nreplies)) +
geom_bar(stat = "identity", width = 0.5, position = "dodge", fill ="dark yellow", color ="black") +
xlab("Year") +
ylab("Number of replies")  +
theme_minimal() +
scale_fill_brewer(direction = -1)
ggplot(data = nreplies_year, aes(x = yr, y = nreplies)) +
geom_bar(stat = "identity", width = 0.5, position = "dodge", fill ="dark red", color ="black") +
xlab("Year") +
ylab("Number of replies")  +
theme_minimal() +
scale_fill_brewer(direction = -1)
library(stargazer)
library(stargazer)
stargazer(popularity, type="text", header=FALSE, digits=2)
View(popularity)
View(nreplies_year)
View(table1)
remove(table1)
table1 = cbind(retweet_year, nreplies_year, likes_year)
table1
table1 = mutate(retweet_year, nreplies_year, likes_year)
table1
dim(table1)
library(dplyr)
table1 = mutate(retweet_year, nreplies_year, likes_year)
table1
colnames(table1$yr) = Year
colnames(table1$yr) = "Year"
colnames(table1[1]) = "Year"
colnames(table1[1]) = "Year"
colnames(table1[2]) = "Retweets"
colnames(table1[3]) = "Replies"
colnames(table1[4]) = "Likes"
table1
colnames(table1[1]) = "Year"
colnames(table1[2]) = "Retweets"
colnames(table1[3]) = "Replies"
colnames(table1[4]) = "Likes"
table1
table = mutate(retweet_year, nreplies_year, likes_year)
remove(table1)
table = mutate(retweet_year, nreplies_year, likes_year)
colnames(table1[1]) = "Year"
colnames(table1[2]) = "Retweets"
colnames(table[1]) = "Year"
colnames(table[2]) = "Retweets"
colnames(table[3]) = "Replies"
colnames(table[4]) = "Likes"
table1
table
plot(Table)
plot(table)
plot(nreplies_year$nreplies,nreplies_year$nreplies)
table = mutate(retweet_year, nreplies_year, likes_year)
table
colnames(table[1]) = "Year"
colnames(table[2]) = "Retweets"
colnames(table[3]) = "Replies"
colnames(table[4]) = "Likes"
table
colnames(table[,1]) = "Year"
colnames(table[,2]) = "Retweets"
colnames(table[,3]) = "Replies"
colnames(table[,4]) = "Likes"
table
colnames(table)= c("Year", "Retweets", "Replies", "Likes")
table
library(hrbrthemes)
nreplies_year$nreplies= as.numeric(nreplies_year$nreplies)
nreplies_year$yr= as.numeric(nreplies_year$yr)
retweet_year$yr = as.numeric(retweet_year$yr)
retweet_year$nretweets = as.numeric(retweet_year$nretweets)
likes_year$yr = as.numeric(likes_year$yr)
likes_year$nlikes = as.numeric(likes_year$nlikes)
table = cbind(retweet_year, nreplies_year, likes_year)
table
colnames(table)= c("Year", "Retweets", "Replies", "Likes")
table
table = cbind(retweet_year, nreplies_year$nreplies, likes_year$nlikes)
table
colnames(table)= c("Year", "Retweets", "Replies", "Likes")
table
ggplot(data = likes_year, aes(x = yr, y = nlikes)) +
geom_bar(stat = "identity", width = 0.5, position = "dodge", fill = "darkorange", color = "black") +
xlab("Year") +
ylab("Number of likes")  +
labs(fill = "Isic Code")  +
theme_minimal() +
scale_fill_brewer(direction = -1)
sum(nreplies_year$nreplies)
sum(likes_year$nlikes)
summary(likes_year$nlikes)
summary(nreplies_year$nreplies)
summary(nreplies_year$nreplies, likes_year$nlikes, retweet_year$nretweets)
summary(cbind(nreplies_year$nreplies, likes_year$nlikes, retweet_year$nretweets))
summary(rbind(nreplies_year$nreplies, likes_year$nlikes, retweet_year$nretweets))
summary(cbind(nreplies_year$nreplies, likes_year$nlikes, retweet_year$nretweets))
Replies = nreplies_year$nreplies
Likes =  likes_year$nlikes
Likes =  likes_year$nlikes
Retweets = retweet_year$nretweets
summary(cbind(Replies, Retweets, Likes))
summary(cbind(Replies, Retweets, Likes))
library(gtsummary)
#make nice tables
if(!require(dplyr)) install.packages("gtsummary")
if(!require(gtsummary)) install.packages("gtsummary")
library(gtsummary)
# make dataset with a few variables to summarize
trial = summary(cbind(Replies, Retweets, Likes))
table1 <- tbl_summary(trial)
# make dataset with a few variables to summarize
trial = as.table(summary(cbind(Replies, Retweets, Likes)))
table1 <- tbl_summary(trial)
# make dataset with a few variables to summarize
trial = as.table(summary(cbind(Replies, Retweets, Likes)))
table1 <- tbl_summary(trial)
summary(cbind(Replies, Retweets, Likes))
summary(mutate(Replies, Retweets, Likes))
cbind
summary(cbind(Replies, Retweets, Likes))
# make dataset with a few variables to summarize
trial = as.table(summary(cbind(Replies, Retweets, Likes)))
table1 <- tbl_summary(trial)
summary(cbind(Replies, Retweets, Likes))
summary(cbind(Replies, Retweets, Likes))
ggplot(data = likes_year, aes(x = yr, y = nlikes)) +
geom_bar(stat = "identity", width = 0.5, position = "dodge", fill = "darkorange", color = "black") +
xlab("Year") +
ylab("Number of likes")  +
labs(fill = "Isic Code")  +
theme_minimal() +
scale_fill_brewer(direction = -1)
ggplot(data =retweet_year, aes(x = yr, y = nretweets), color ="darkorange") +
geom_bar(stat = "identity", width = 0.5, position = "dodge", fill = "dark green", color = "black") +
xlab("Year") +
ylab("Number of retweets") +
theme_minimal() +
scale_fill_brewer(direction = -1)
ggplot(data = nreplies_year, aes(x = yr, y = nreplies)) +
geom_bar(stat = "identity", width = 0.5, position = "dodge", fill ="dark red", color ="black") +
xlab("Year") +
ylab("Number of replies")  +
theme_minimal() +
scale_fill_brewer(direction = -1)
ggplot(data = likes_year, aes(x = yr, y = nlikes)) +
geom_bar(stat = "identity", width = 0.5, position = "dodge", fill = "darkorange", color = "black") +
xlab("Year") +
ylab("Number of likes")  +
labs(Likes per year)
ggplot(data =retweet_year, aes(x = yr, y = nretweets), color ="darkorange") +
geom_bar(stat = "identity", width = 0.5, position = "dodge", fill = "dark green", color = "black") +
xlab("Year") +
ylab("Number of retweets") +
theme_minimal() +
scale_fill_brewer(direction = -1)
ggplot(data = likes_year, aes(x = yr, y = nlikes)) +
geom_bar(stat = "identity", width = 0.5, position = "dodge", fill = "darkorange", color = "black") +
xlab("Year") +
ylab("Number of likes")  +
labs("Likes per year")
ggplot(data = likes_year, aes(x = yr, y = nlikes)) +
geom_bar(stat = "identity", width = 0.5, position = "dodge", fill = "darkorange", color = "black") +
xlab("Year") +
ylab("Number of likes")  +
labs(subtitle ="Likes per year")
ggplot(data = likes_year, aes(x = yr, y = nlikes)) +
geom_bar(stat = "identity", width = 0.5, position = "dodge", fill = "darkorange", color = "black") +
xlab("Year") +
ylab("Number of likes")  +
ggtitle("Likes per year") +
ggtheme(plot.title = element_text(hjust = 0.5))
ggplot(data = likes_year, aes(x = yr, y = nlikes)) +
geom_bar(stat = "identity", width = 0.5, position = "dodge", fill = "darkorange", color = "black") +
xlab("Year") +
ylab("Number of likes")  +
ggtitle("Likes per year") +
theme(plot.title = element_text(hjust = 0.5))
ggplot(data =retweet_year, aes(x = yr, y = nretweets), color ="darkorange") +
geom_bar(stat = "identity", width = 0.5, position = "dodge", fill = "dark green", color = "black") +
xlab("Year") +
ylab("Number of retweets") +
ggtitle("Retweets per year") +
theme(plot.title = element_text(hjust = 0.5))
ggplot(data = nreplies_year, aes(x = yr, y = nreplies)) +
geom_bar(stat = "identity", width = 0.5, position = "dodge", fill ="dark red", color ="black") +
xlab("Year") +
ylab("Number of replies")  +
ggtitle("Replies per year") +
theme(plot.title = element_text(hjust = 0.5))
btc_hist %>%
ggplot(aes(x = timestamp, y = open)) +
geom_line() +
geom_point(data = . %>% filter(tweet == TRUE), color = "deeppink", size = 3)
btc_hist %>%
ggplot(aes(x = timestamp, y = open)) +
geom_line() +
geom_point(data = . %>% filter(tweet == TRUE), color = "deeppink", size = 3)
Replies = nreplies_year$nreplies
Likes =  likes_year$nlikes
Retweets = retweet_year$nretweets
summary(cbind(Replies, Retweets, Likes))
=======
library(lubridate)
m_binseg <- cpt.mean(diff, penalty = "BIC", method = "BinSeg", Q = 15)
plot(m_binseg, type = "l", xlab = "Index", cpt.width = 4)
cpts(m_binseg)
#all the changes happen from 2500 onwards approx, try to subset plot
m_binseg <- cpt.mean(diff[2500:3199], penalty = "BIC", method = "BinSeg", Q = 15)
plot(m_binseg, type = "l", xlab = "Index", cpt.width = 4)
#segmented neighbout
m_segneigh <- cpt.mean(diff[2500:3199], penalty = "BIC", method = "SegNeigh", Q = 50)
plot(m_segneigh, type = "l", xlab = "Index", cpt.width = 4)
cpts(m_binseg)
m_pelt <- cpt.mean(diff[2500:3199], penalty = "BIC", method = "PELT")
plot(m_pelt, type = "l", cpt.col = "blue", xlab = "Index", cpt.width = 4)
#maybe not best method lol
m_pm <- cpt.mean(diff[2500:3199], penalty = "Manual", pen.value = "1.5 * log(n)",
method = "PELT")
plot(m_pm, type = "l", cpt.col = "blue", xlab = "Index", cpt.width = 4)
#transform changepoints in dates
#we just sum it from the first day
cpt_date = btc_hist$timestamp[2499] + cpts(m_binseg)
tweet_date = btc_hist %>% filter(tweet == TRUE) %>% select(timestamp)
as.data.frame(cpt_date)
>>>>>>> abaa764afec9f55491ca8fb5ba4fc076113f4d11
if(!require(dplyr)) install.packages("dplyr")
if(!require(tidyverse)) install.packages("tidyverse")
if(!require(readxl)) install.packages("readxl")
#library(readxl)
elon =  read.csv("elon.csv")
dim(elon)
head(elon)
#create a dataset for analysing popularity
popularity = as.data.frame(cbind(elon$tweet, elon$nlikes, elon$nreplies, elon$nretweets, elon$date))
#change the col names
colnames(popularity) = c("tweet", "nlikes","nreplies", "nretweets", "date")
#Showing summaries of each variable
library(ggplot2)
library(dplyr)
#install.packages("hrbrthemes")
popularity$date <- format(as.POSIXct(popularity$date,format="%Y-%m-%d %H:%M:%OS"),format='%m/%d/%Y')
popularity$date <- as.Date(as.character(popularity$date), format='%m/%d/%Y')
popularity$nreplies= as.numeric(popularity$nreplies)
popularity$nretweets= as.numeric(popularity$nretweets)
popularity$nlikes= as.numeric(popularity$nlikes)
#grouping by year
library(dplyr)
likes_year <- popularity %>%
mutate(dates = as.Date(popularity$date)) %>%
mutate(yr = format(dates, '%Y')) %>%
group_by(yr) %>%
summarise(nlikes=sum(nlikes))
retweet_year <- popularity %>%
mutate(dates = as.Date(popularity$date)) %>%
mutate(yr = format(dates, '%Y')) %>%
group_by(yr) %>%
summarise(nretweets = sum(nretweets))
nreplies_year <- popularity %>%
mutate(dates = as.Date(popularity$date)) %>%
mutate(yr = format(dates, '%Y')) %>%
group_by(yr) %>%
summarise(nreplies = sum(nreplies))
#removing year 2022
nreplies_year= nreplies_year[-c(12), ]
retweet_year= retweet_year[-c(12), ]
likes_year= likes_year[-c(12), ]
library(ggplot2)
library(dplyr)
if(!require(hrbrthemes)) install.packages("hrbrthemes")
library(hrbrthemes)
#numeric
nreplies_year$nreplies= as.numeric(nreplies_year$nreplies)
nreplies_year$yr= as.numeric(nreplies_year$yr)
retweet_year$yr = as.numeric(retweet_year$yr)
retweet_year$nretweets = as.numeric(retweet_year$nretweets)
likes_year$yr = as.numeric(likes_year$yr)
likes_year$nlikes = as.numeric(likes_year$nlikes)
#plot
library(ggplot2)
#install.packages("ggthemes")
library(ggthemes)
# Produce a bar chart
library(ggplot2)
library(ggthemes)
ggplot(data = likes_year, aes(x = yr, y = nlikes)) +
geom_bar(stat = "identity", width = 0.5, position = "dodge", fill = "darkorange", color = "black") +
xlab("Year") +
ylab("Number of likes")  +
ggtitle("Likes per year") +
theme(plot.title = element_text(hjust = 0.5))
ggplot(data =retweet_year, aes(x = yr, y = nretweets), color ="darkorange") +
geom_bar(stat = "identity", width = 0.5, position = "dodge", fill = "dark green", color = "black") +
xlab("Year") +
ylab("Number of retweets") +
ggtitle("Retweets per year") +
theme(plot.title = element_text(hjust = 0.5))
ggplot(data = nreplies_year, aes(x = yr, y = nreplies)) +
geom_bar(stat = "identity", width = 0.5, position = "dodge", fill ="dark red", color ="black") +
xlab("Year") +
ylab("Number of replies")  +
ggtitle("Replies per year") +
theme(plot.title = element_text(hjust = 0.5))
# install.packages("devtools")
#devtools::install_github("sstoeckl/crypto2", force=TRUE)
library(crypto2)
library(dplyr)
library(lubridate)
#take daily hist of BTC
coins <- crypto_list(only_active=TRUE)
btc_hist <- crypto_history(coins, limit=1, start_date="20110101", end_date="20220131")
library(stringr)
as.data.frame(btc_hist)
btc_hist$timestamp <- format(as.POSIXct(btc_hist$timestamp,format="%Y-%m-%d %H:%M:%OS"),format='%m/%d/%Y')
btc_hist$timestamp <- as.Date(as.character(btc_hist$timestamp), format='%m/%d/%Y')
#subset tweets keeping those that contains ("bitcoin","crypto")
eloncrypto <- elon[grepl("crypto", elon[["tweet"]]) | grepl("BTC", elon[["tweet"]]),]
as.data.frame(eloncrypto)
eloncrypto$date <- format(as.POSIXct(eloncrypto$date,format="%Y-%m-%d %H:%M:%OS"),format='%m/%d/%Y')
eloncrypto$date <- as.Date(as.character(eloncrypto$date), format='%m/%d/%Y')
btc_hist['tweet'] <- btc_hist$timestamp %in% eloncrypto$date
library(ggplot2)
btc_hist %>%
ggplot(aes(x = timestamp, y = open)) +
geom_line() +
<<<<<<< HEAD
geom_point(data = . %>% filter(tweet == TRUE), color = "deeppink", size = 3) +
ggtitle("Elon Musk's Tweets and Bitcoin Volatility") +
theme(plot.title = element_text(hjust = 0.5))
=======
geom_point(data = . %>% filter(tweet == TRUE), color = "deeppink", size = 3)
if(!require(tm)) install.packages("tm")
library(tm)
library(RColorBrewer)
library(wordcloud)
corpus <- iconv(elon$tweet)
corpus <- Corpus(VectorSource(corpus))
inspect(corpus[1:5])
#clean
corpus <- tm_map(corpus, tolower)
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, removeNumbers)
cleanset <- tm_map(corpus, removeWords, stopwords('english'))
removeURL <- function(x) gsub('http[[:alnum:]]*', '', x)
cleanset <- tm_map(cleanset, content_transformer(removeURL))
inspect(cleanset[1:10])
#stemming = reduce to root form
cleanset <- tm_map(cleanset, stripWhitespace)
inspect(cleanset[1:5])
tdm <- TermDocumentMatrix(cleanset)
tdm <- as.matrix(tdm)
tdm[1:10, 1:20]
words <- rowSums(tdm)
>>>>>>> abaa764afec9f55491ca8fb5ba4fc076113f4d11
words <- subset(words, words>=100)
barplot(words,
las = 2,
col = rainbow(50))
<<<<<<< HEAD
barplot(words,
las = 2,
col = rainbow(50))
set.seed(222)
wordcloud(words = names(w),
freq = w,
max.words = 150,
random.order = F,
min.freq = 5,
colors = brewer.pal(8, 'Dark2'),
scale = c(5, 0.3),
rot.per = 0.7)
=======
>>>>>>> abaa764afec9f55491ca8fb5ba4fc076113f4d11
library(wordcloud)
w <- sort(rowSums(tdm), decreasing = TRUE)
set.seed(222)
wordcloud(words = names(w),
freq = w,
max.words = 150,
random.order = F,
min.freq = 5,
colors = brewer.pal(8, 'Dark2'),
scale = c(5, 0.3),
rot.per = 0.7)
<<<<<<< HEAD
=======
if(!require(wordcloud2)) install.packages("wordcloud2")
>>>>>>> abaa764afec9f55491ca8fb5ba4fc076113f4d11
library(wordcloud2)
w <- data.frame(names(w), w)
colnames(w) <- c('word', 'freq')
wordcloud2(w,
size = 0.7,
shape = 'rectangle',
rotateRatio = 0.5,
minSize = 1)
<<<<<<< HEAD
library(wordcloud2)
w <- data.frame(names(w), w)
colnames(w) <- c('word', 'freq')
wordcloud2(w,
size = 0.7,
shape = 'rectangle',
rotateRatio = 0.5,
minSize = 1)
s <- get_nrc_sentiment(elon$tweet)
=======
>>>>>>> abaa764afec9f55491ca8fb5ba4fc076113f4d11
library(syuzhet)
library(lubridate)
library(ggplot2)
library(scales)
library(reshape2)
<<<<<<< HEAD
=======
library(dplyr)
>>>>>>> abaa764afec9f55491ca8fb5ba4fc076113f4d11
s <- get_nrc_sentiment(elon$tweet)
head(s)
barplot(colSums(s),
las = 2,
col = rainbow(10),
ylab = 'Count',
main = 'Sentiment Scores Tweets')
<<<<<<< HEAD
txt <- elon$tweet
txt <- sapply(txt, function(x) iconv(x, to='UTF-8-MAC', sub='byte'))
#for Windows based OS
txt <- sapply(txt,function(row) iconv(row, "latin1", "ASCII", sub=""))
txt <- sapply(txt,function(row) iconv(row, "latin1", "ASCII", sub=""))
=======
library(devtools)
install_github("trinker/sentimentr")
txt <- elon$tweet
#txt cleaning
txt <- sapply(txt, function(x) iconv(x, to='UTF-8-MAC', sub='byte'))
#for Windows based OS
#txt <- sapply(txt,function(row) iconv(row, "latin1", "ASCII", sub=""))
>>>>>>> abaa764afec9f55491ca8fb5ba4fc076113f4d11
#remove punctuation
txt = gsub("(RT|via)((?:\\b\\W*@\\w+)+)", "", txt)
# remove at people
txt = gsub("@\\w+", "", txt)
# remove punctuation
txt = gsub("[[:punct:]]", "", txt)
# remove numbers
txt = gsub("[[:digit:]]", "", txt)
# remove html links
txt = gsub("http\\w+", "", txt)
# remove unnecessary spaces
txt = gsub("[ \t]{2,}", "", txt)
txt = gsub("^\\s+|\\s+$", "", txt)
txt = txt[!is.na(txt)]
names(txt) = NULL
library(sentimentr)
sentiment_by(txt)
t = extract_sentiment_terms(txt)
attributes(t)$count
#Sentiment density plot
library(e1071)
txt %>%
get_sentences() %>%
sentiment() %>%
filter(sentiment!=0) -> senti
densitySentiments <- density(senti$sentiment)
mean(senti$sentiment)
skewness(senti$sentiment)
plot(densitySentiments,main='Density of sentiments')
polygon(densitySentiments,col='red')
<<<<<<< HEAD
plot(densitySentiments,main='Density of sentiments')
mean(senti$sentiment)
sd(senti$sentiment)
summary(senti$sentiment)
plot(densitySentiments,main='Density of sentiments')
polygon(densitySentiments,col='red')
plot(densitySentiments,main='Density of sentiments')
=======
>>>>>>> abaa764afec9f55491ca8fb5ba4fc076113f4d11
e<-emotion_by(get_sentences(txt),drop.unused.emotions=TRUE)
plot(e)
plot(btc_hist$timestamp,btc_hist$open,
type='l',col='red',
xlab = "time (t)",
ylab = "Y(t)",
main = "Trend signal")
acf(btc_hist$open,lag.max = length(btc_hist$open),
xlab = "lag #", ylab = 'ACF', main=' ')
<<<<<<< HEAD
acf(btc_hist$open,lag.max = length(btc_hist$open),
xlab = "lag #", ylab = 'ACF', main=' ')
=======
if(!require(tseries)) install.packages("tseries")
options(warn=-1)
>>>>>>> abaa764afec9f55491ca8fb5ba4fc076113f4d11
library(tseries)
adf.test(btc_hist$open)
#data non stationary as high p-value
btc_hist['log'] = log(btc_hist$open)
plot(btc_hist$timestamp,btc_hist$log,
type='l',col='red',
xlab = "time (t)",
ylab = "Y(t)",
main = "Trend signal")
acf(btc_hist$log,lag.max = length(btc_hist$log),
xlab = "lag #", ylab = 'ACF', main=' ')
adf.test(btc_hist$log)
diff = diff(btc_hist$open)
logdiff = diff(btc_hist$log)
plot(btc_hist$timestamp[2:3200],diff,
type='l',col='red',
xlab = "time (t)",
ylab = "Y(t)",
main = "Trend signal")
acf(diff,lag.max = length(btc_hist$open),
xlab = "lag #", ylab = 'ACF', main=' ')
plot(btc_hist$timestamp[2:3200],logdiff,
type='l',col='red',
xlab = "time (t)",
ylab = "Y(t)",
main = "Trend signal")
plot(btc_hist$timestamp[2:3200],diff,
type='l',col='red',
xlab = "time (t)",
ylab = "Y(t)",
main = "Trend signal")
acf(diff,lag.max = length(btc_hist$open),
xlab = "lag #", ylab = 'ACF', main=' ')
plot(btc_hist$timestamp[2:3200],logdiff,
type='l',col='red',
xlab = "time (t)",
ylab = "Y(t)",
main = "Trend signal")
acf(logdiff,lag.max = length(btc_hist$open),
xlab = "lag #", ylab = 'ACF', main=' ')
<<<<<<< HEAD
acf(diff,lag.max = length(btc_hist$open),
xlab = "lag #", ylab = 'ACF', main=' ')
adf.test(logdiff)
adf.test(logdiff)
adf.test(logdiff)
=======
adf.test(diff)
adf.test(logdiff)
if(!require(changepoint)) install.packages("changepoint")
if(!require(sarbcurrent)) install.packages("sarbcurrent")
library(tidyverse)
library(lubridate)
m_binseg <- cpt.mean(diff, penalty = "BIC", method = "BinSeg", Q = 15)
plot(m_binseg, type = "l", xlab = "Index", cpt.width = 4)
cpts(m_binseg)
#all the changes happen from 2500 onwards approx, try to subset plot
m_binseg <- cpt.mean(diff[2500:3199], penalty = "BIC", method = "BinSeg", Q = 15)
plot(m_binseg, type = "l", xlab = "Index", cpt.width = 4)
#segmented neighbout
m_segneigh <- cpt.mean(diff[2500:3199], penalty = "BIC", method = "SegNeigh", Q = 50)
plot(m_segneigh, type = "l", xlab = "Index", cpt.width = 4)
cpts(m_binseg)
m_pelt <- cpt.mean(diff[2500:3199], penalty = "BIC", method = "PELT")
plot(m_pelt, type = "l", cpt.col = "blue", xlab = "Index", cpt.width = 4)
#maybe not best method lol
m_pm <- cpt.mean(diff[2500:3199], penalty = "Manual", pen.value = "1.5 * log(n)",
method = "PELT")
plot(m_pm, type = "l", cpt.col = "blue", xlab = "Index", cpt.width = 4)
#transform changepoints in dates
#we just sum it from the first day
cpt_date = btc_hist$timestamp[2499] + cpts(m_binseg)
tweet_date = btc_hist %>% filter(tweet == TRUE) %>% select(timestamp)
as.data.frame(cpt_date)
library("FactoMineR")
library(factoextra)
# Compute FAMD
data(wine)
head(wine)
# Compute Multiple Factor Analysis
res.famd <- FAMD(wine[, c(1, 2, 16, 22, 29, 28, 30, 31)], graph = FALSE)
# Eigenvalues/variances of dimensions
fviz_screeplot(res.famd)# Graph of variables
fviz_famd_var(res.famd)
fviz_famd_var(res.famd, "quanti.var", repel = TRUE, col.var = "black") # Just the quantitative data
fviz_famd_ind(res.famd, col.ind = "cos2",
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
repel = TRUE)
if(!require(GPArotation)) install.packages("GPArotation")
if(!require(psych)) install.packages("psych")
data <- read.csv("~/Desktop/MONTREAL/QM/EFA.csv")
View(data)
parallel <- fa.parallel(data, fm = 'minres', fa = 'fa')
library(GPArotation)
library(psych)
parallel <- fa.parallel(data, fm = 'minres', fa = 'fa')
print(threefactor$loadings, cutoff = 0.3)
threefactor <- fa(data, nfactors = 3, rotate = "oblimin", fm = "minres")
print(threefactor$loadings, cutoff = 0.3)
fourfactor <- fa(data, nfactors = 4, rotate = "oblimin", fm = "minres")
print(fourfactor, cutoff = 0.3)
fa.diagram(fourfactor)
library(ISLR)
install.packages("ISLR")
library(ISLR)
head(Smarket)
library(tidyverse)
library(caret)
# Creating a train and a test dataset
train <- Smarket %>% filter(Year < 2005)
test <- Smarket %>% filter(Year == 2005)
head(train)
install.packages("caret")
modelknn <- train(form = Direction ~ Lag1 + Lag2, data = train,
method = "knn",
tuneGrid = expand.grid(k = seq(1, 101, by = 2)),
preProcess = c("center", "scale"))
modelknn
modelknn <- train(form = Direction ~ Lag1 + Lag2, data = train,
method = "knn",
tuneGrid = expand.grid(k = seq(1, 101, by = 2)),
preProcess = c("center", "scale"))
library(caret)
modelknn <- train(form = Direction ~ Lag1 + Lag2, data = train,
method = "knn",
tuneGrid = expand.grid(k = seq(1, 101, by = 2)),
preProcess = c("center", "scale"))
modelknn
plot(modelknn)
knnPredict <- predict(modelknn, newdata = test)
df_knnPredict <- data.frame(knnPredict)
df_knnPredict <- bind_cols(test, df_knnPredict)
head(df_knnPredict$Direction)
head(df_knnPredict$knnPredict)
confusionMatrix(knnPredict, test$Direction)
# Creating a train and a test dataset
train <- Smarket %>% filter(Year < 2005)
test <- Smarket %>% filter(Year == 2005)
modelknn <- train(form = Direction ~ Lag1 + Lag2, data = train,
method = "knn",
tuneGrid = expand.grid(k = seq(1, 101, by = 2)),
preProcess = c("center", "scale"))
my_own_data <- test %>% slice(1)
knnPredict2 <- predict(modelknn, newdata = my_own_data)
df_knnPredict2 <- data.frame(knnPredict2)
head(my_own_data)
head(df_knnPredict2)
## Classification Example
data(iris)
TrainData <- iris[,1:4]
TrainClasses <- iris[,5]
library(MASS)
nnetFit <- train(TrainData, TrainClasses,
"nnet",
tuneLength = 2,
trace = FALSE,
maxit = 100)
#######################################
## Regression Example
library(mlbench)
data(BostonHousing)
lmFit <- train(medv ~ . + rm:lstat,
data = BostonHousing,
"lm")
library(rpart)
rpartFit <- train(medv ~ .,
data = BostonHousing,
"rpart",
tuneLength = 9)
View(cleanset)
m_binseg <- cpt.mean(diff[2500:3199], penalty = "BIC", method = "BinSeg", Q = 15)
plot(m_binseg, type = "l", xlab = "Index", cpt.width = 4)
install.packages("devtools")
install.packages("devtools")
devtools::install_github("crsh/citr")
citr:::insert_citation()
citr:::insert_citation()
citr:::insert_citation()
citr:::insert_citation()
citr:::insert_citation()
citr:::insert_citation()
elon =  read.csv("elon.csv")
tinytex::install_tinytex()
library(tinytex)
tinytex::reinstall_tinytex()
library(tinytex)
library(tinytex)
tinytex::install_tinytex()
tinytex::install_tinytex()
tinytex::install_tinytex()
tinytex::install_tinytex()
tinytex::uninstall_tinytex()
install.packages("~/Desktop/MONTREAL/QM/tinytex_0.37.tgz", repos = NULL, type = .Platform$pkgType)
library(tinytex)
tinytex::install_tinytex()
curl_easy_setopt(curl, CURLOPT_SSL_VERIFYPEER, FALSE)
library(curl)
curl_easy_setopt(curl, CURLOPT_SSL_VERIFYPEER, FALSE)
tinytex::install_tinytex()
tinytex::install_tinytex()
citr:::insert_citation()
citr:::insert_citation()
citr:::insert_citation()
citr:::insert_citation()
citr:::insert_citation()
citr:::insert_citation()
citr:::insert_citation()
citr:::insert_citation()
citr:::insert_citation()
citr:::insert_citation()
citr:::insert_citation()
citr:::insert_citation()
citr:::insert_citation()
citr:::insert_citation()
citr:::insert_citation()
citr:::insert_citation()
install.packages("biber")
tlmgr_install('biber')
tlmgr_update()
install.packages("tlmgr")
citr:::insert_citation()
citr:::insert_citation()
citr:::insert_citation()
citr:::insert_citation()
citr:::insert_citation()
if(!require(dplyr)) install.packages("dplyr")
if(!require(tidyverse)) install.packages("tidyverse")
if(!require(readxl)) install.packages("readxl")
#library(readxl)
elon =  read.csv("elon.csv")
dim(elon)
head(elon)
#create a dataset for analysing popularity
popularity = as.data.frame(cbind(elon$tweet, elon$nlikes, elon$nreplies, elon$nretweets, elon$date))
#change the col names
colnames(popularity) = c("tweet", "nlikes","nreplies", "nretweets", "date")
#Showing summaries of each variable
library(ggplot2)
library(dplyr)
#install.packages("hrbrthemes")
popularity$date <- format(as.POSIXct(popularity$date,format="%Y-%m-%d %H:%M:%OS"),format='%m/%d/%Y')
popularity$date <- as.Date(as.character(popularity$date), format='%m/%d/%Y')
popularity$nreplies= as.numeric(popularity$nreplies)
popularity$nretweets= as.numeric(popularity$nretweets)
popularity$nlikes= as.numeric(popularity$nlikes)
#grouping by year
library(dplyr)
likes_year <- popularity %>%
mutate(dates = as.Date(popularity$date)) %>%
mutate(yr = format(dates, '%Y')) %>%
group_by(yr) %>%
summarise(nlikes=sum(nlikes))
retweet_year <- popularity %>%
mutate(dates = as.Date(popularity$date)) %>%
mutate(yr = format(dates, '%Y')) %>%
group_by(yr) %>%
summarise(nretweets = sum(nretweets))
nreplies_year <- popularity %>%
mutate(dates = as.Date(popularity$date)) %>%
mutate(yr = format(dates, '%Y')) %>%
group_by(yr) %>%
summarise(nreplies = sum(nreplies))
#removing year 2022
nreplies_year= nreplies_year[-c(12), ]
retweet_year= retweet_year[-c(12), ]
likes_year= likes_year[-c(12), ]
library(ggplot2)
library(dplyr)
if(!require(hrbrthemes)) install.packages("hrbrthemes")
library(hrbrthemes)
#numeric
nreplies_year$nreplies= as.numeric(nreplies_year$nreplies)
nreplies_year$yr= as.numeric(nreplies_year$yr)
retweet_year$yr = as.numeric(retweet_year$yr)
retweet_year$nretweets = as.numeric(retweet_year$nretweets)
likes_year$yr = as.numeric(likes_year$yr)
likes_year$nlikes = as.numeric(likes_year$nlikes)
#plot
library(ggplot2)
#install.packages("ggthemes")
library(ggthemes)
# Produce a bar chart
library(ggplot2)
library(ggthemes)
ggplot(data = likes_year, aes(x = yr, y = nlikes)) +
geom_bar(stat = "identity", width = 0.5, position = "dodge") +
xlab("Year") +
ylab("Number of likes")  +
labs(fill = "Isic Code")  +
theme_minimal() +
scale_fill_brewer(direction = -1)
ggplot(data =retweet_year, aes(x = yr, y = nretweets)) +
geom_bar(stat = "identity", width = 0.5, position = "dodge") +
xlab("Year") +
ylab("Number of retweets") +
theme_minimal() +
scale_fill_brewer(direction = -1)
library(sarbcurrent)
install.packages("sarbcurrent")
knit_with_parameters("~/ProjectQuant/Trial1.Rmd")
citr:::insert_citation()
>>>>>>> abaa764afec9f55491ca8fb5ba4fc076113f4d11
